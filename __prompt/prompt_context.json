{
    "README.md": "# maldinio_ai",
    "dist/maldinio_ai-0.1.1-py3-none-any.whl": "Error reading file: 'utf-8' codec can't decode byte 0xe0 in position 10: invalid continuation byte",
    "dist/maldinio_ai-0.1.1.tar.gz": "Error reading file: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
    "setup.py": "from setuptools import setup, find_packages\n\nsetup(\n    name='maldinio_ai',\n    version='0.1.1',\n    packages=find_packages(),\n    install_requires=[\n        \"tiktoken>=0.4.0\",\n        \"openai>=1.3.7\",\n    ],\n    description='A utility package for AI prompt management and prompt processing.',\n    author='Mehdi Nabhani',\n    author_email='mehdi@nabhani.de',\n    keywords=['AI', 'NLP', 'LLM', 'Prompt Management'],\n\n)\n",
    "tools/create_project_folder.py": "import os\nimport json\nfrom datetime import datetime\nfrom ai import ModuleMemory, NLPProcessor\n\nclass CreateProjectFolder:\n    def __init__(self, memory: ModuleMemory):\n        self.main_key = \"project\"\n        self.key = \"files\"\n        self.sub_key = \"project_folder\"\n        self.memory = memory\n        self.root_folder = \"temp_project\"\n        self.project_name = \"project_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        self.full_path = os.path.join(self.root_folder, self.project_name)\n        self.full_path_prompts = os.path.join(self.root_folder, self.project_name, \"prompts\")\n        self.full_path_responses = os.path.join(self.root_folder, self.project_name, \"responses\")\n        self.full_path_output = os.path.join(self.root_folder, self.project_name, \"output\")\n\n    def get_key(self):\n        return self.key\n    \n    def get_main_key(self):\n        return self.main_key\n    \n    def get_sub_key(self):\n        return self.sub_key\n\n    def execute(self):\n        self.create_project_directory()\n\n    def create_project_directory(self):\n        if not os.path.exists(self.full_path):\n            os.makedirs(self.full_path)\n            print(f\"Created project directory: {self.full_path}\")\n        else:\n            print(f\"Project directory already exists: {self.full_path}\")\n                \n        if not os.path.exists(self.full_path_prompts):\n            os.makedirs(self.full_path_prompts)\n            print(f\"Created prompts directory: {self.full_path_prompts}\")\n        else:\n            print(f\"Prompts directory already exists: {self.full_path_prompts}\")\n            \n        if not os.path.exists(self.full_path_responses):\n            os.makedirs(self.full_path_responses)\n            print(f\"Created responses directory: {self.full_path_responses}\")\n        else:\n            print(f\"Responses directory already exists: {self.full_path_responses}\")\n            \n        if not os.path.exists(self.full_path_output):\n            os.makedirs(self.full_path_output)\n            print(f\"Created output directory: {self.full_path_output}\")\n        else:\n            print(f\"Output directory already exists: {self.full_path_output}\")\n            \n        self.memory.create([self.main_key, self.key, self.sub_key], self.full_path)\n        self.memory.create([self.main_key, self.key, \"prompt_folder\"], self.full_path_prompts)\n        self.memory.create([self.main_key, self.key, \"response_folder\"], self.full_path_responses)\n        self.memory.create([self.main_key, self.key, \"output_folder\"], self.full_path_output)\n",
    "tools/load_project.py": "# modules/load_project.py\n\nimport os\nimport json\nfrom ai import ModuleMemory, NLPProcessor\n\nclass LoadProject:\n    def __init__(self, memory: ModuleMemory):\n        self.main_key = \"project\"\n        self.key = \"initial_project_details\"\n        self.memory = memory\n        \n    def get_key(self):\n        return self.key\n    \n    def get_main_subkey(self):\n        return self.main_subkey\n    \n    def execute(self):\n        # Get the current working directory\n        current_directory = os.getcwd()\n\n        # Filename you want to join with the current directory\n        filename = \"project.json\"\n\n        # Join the current directory with the filename\n        project_file_path = os.path.join(current_directory, filename)\n        \n        print (\"loading project:\", project_file_path)\n\n        self.load_project(project_file_path)\n        # self.enhance_project()\n\n    def load_project(self, project_file):\n        \"\"\"\n        Load project details from a JSON file and store them in memory.\n        \"\"\"\n        try:\n            with open(project_file, 'r') as file:\n                project_data = json.load(file)\n                self.memory.create([self.main_key, self.key], project_data)\n                print(f\"Project '{project_data['name']}' loaded successfully.\")\n        except FileNotFoundError:\n            print(f\"Error: File '{project_file}' not found.\")\n        except json.JSONDecodeError:\n            print(\"Error: JSON decoding error.\")\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n\n",
    "utils/verification_utils.py": "import json\nfrom utils.json_utils import extract_json_from_message, extract_json_string_from_message\n\n\ndef validate_json_structure_noarray(json_data, expected_structure):\n    for key, value_type in expected_structure.items():\n        print (key, value_type)\n        if key not in json_data or not isinstance(json_data[key], value_type):\n            return False\n    return True\n\ndef validate_json_structure(json_data, expected_structure):\n    for key, value_type in expected_structure.items():\n        print ('key, value_type', key, value_type)\n        \n        \n        if key not in json_data:\n            print ('key not in json_data')\n            \n            return False\n        if isinstance(value_type, list):\n            print ('value_type is list')\n            if not isinstance(json_data[key], list):\n                print ('json_data[key] is not list')\n                return False\n            # Validate each item in the array\n            for item in json_data[key]:\n                print ('item', item)\n                if not isinstance(item, value_type[0]):\n                    print ('item is not value_type[0]')\n                    return False\n        else:\n            print ('value_type is not list')\n            if not isinstance(json_data[key], value_type):\n                print ('json_data[key] is not value_type')\n                return False\n    return True\n\n\ndef validate_data(data):\n    # Add your specific validation logic here\n    return True\n\ndef validate_subtasks(subtasks):\n    for subtask in subtasks:\n        if not isinstance(subtask, dict):\n            return False\n        expected_keys = [\"id\", \"name\", \"description\", \"status\"]\n        for key in expected_keys:\n            if key not in subtask or not isinstance(subtask[key], str):\n                return False\n    return True",
    "utils/json_utils.py": "import re\nimport json\n\ndef fix_json(json_data):\n    try:\n        # Attempt to directly parse the JSON first\n        return json.loads(json_data)\n    except json.JSONDecodeError:\n        try:\n            # Attempt to fix single quotes and re-parse\n            fixed_json = json_data.replace(\"'\", '\"')\n            return json.loads(fixed_json)\n        except json.JSONDecodeError:\n            # Handle other JSON errors\n            return None\n\ndef verify_json(json_data, structure):\n    \n    debug = False\n\n    if debug == True:\n        print (\"json_data: \", json_data)\n        print (\"structure: \", structure)\n        print (\"--------------------------------\")\n        print ()\n        \n        data = json.loads(json_data)\n\n        comparison_result = compare_structure(data, structure)\n\n    data = fix_json(json_data)\n    if data is not None:\n        comparison_result = compare_structure(data, structure)\n        return comparison_result\n    else:\n        # Handle other JSON errors\n        return False\n        \ndef compare_structure(data, structure):\n    if isinstance(structure, type):\n        return isinstance(data, structure)\n\n    if isinstance(structure, dict):\n        for key, value_structure in structure.items():\n            if key not in data or not compare_structure(data[key], value_structure):\n                return False\n\n    elif isinstance(structure, list):\n        # Handling list of primitives separately\n        if isinstance(structure[0], type):\n            return all(isinstance(item, structure[0]) for item in data)\n        else:\n            if not all(isinstance(item, type(structure[0])) for item in data):\n                return False\n            for item in data:\n                if not compare_structure(item, structure[0]):\n                    return False\n\n    return True\n\n\n\ndef generate_string_from_json(json_obj):\n    def process_value(value):\n        if isinstance(value, dict):\n            return generate_string_from_json(value)\n        elif isinstance(value, list):\n            if value:\n                element = process_value(value[0])\n                return f\"[{element}]\"\n            else:\n                return \"[]\"\n        else:\n            return str(value)\n\n\n    string_representation = \"{\"\n    for key, value in json_obj.items():\n        processed_value = process_value(value)\n        string_representation += f'\"{key}\": {processed_value}, '\n    string_representation = string_representation.rstrip(\", \")\n    string_representation += \"}\"\n    return string_representation\n\n# Example usage\nexpected_structure = {\n    \"nlp_task\": str,\n    \"task_description\": str,\n    \"nested_array\": [str],\n    \"nested_object\": {\n        \"property1\": int,\n        \"property2\": float\n    }\n}\n\n\n\n\ndef convert_json_to_python_object(json_dict):\n    # Define a dictionary to store the converted Python object structure\n    python_object = {}\n\n    # Define a mapping from type string to Python type\n    types_mapping = {\n        \"str\": str,\n        \"int\": int,\n        \"float\": float,\n        \"bool\": bool,\n        \"null\": type(None),\n        \"list\": list,\n        \"tuple\": tuple,\n        \"dict\": dict,\n        \"set\": set,\n        \"frozenset\": frozenset,\n        \"complex\": complex,\n        \"bytes\": bytes,\n        \"bytearray\": bytearray\n    }\n\n    # Iterate over each key-value pair in the JSON dictionary\n    for key, value in json_dict.items():\n        # If the value is a list, recursively call this function for each element\n        if isinstance(value, list):\n            python_object[key] = [convert_json_to_python_object(v) if isinstance(v, dict) else types_mapping.get(v, v) for v in value]\n        # If the value is a nested dictionary, recursively call this function\n        elif isinstance(value, dict):\n            python_object[key] = convert_json_to_python_object(value)\n        # If the value is a type string, convert it to the corresponding Python type\n        else:\n            python_object[key] = types_mapping.get(value, value)\n\n    return python_object\n\n\n\n# Example usage:\nobj = {\n    \"step_number\": int,\n    \"step_description\": str,\n    \"name\": str,\n    \"description\": str,\n    \"tasks\": [\n        {\n            \"task_name\": str,\n            \"task_type\": str,\n            \"tree_of_thought\": bool,\n            \"quality_check\": bool,\n            \"input_values\": [str],\n            \"output_values\": [str],\n            \"prompt\": str,\n            \"expected_structure\": {\n                \"functionalities\": [str]\n            },\n            \"replacements\": dict\n        }\n    ]\n}\n\n\ndef generate_expected_structure_string(expected_structure):\n    expected_structure_object = convert_json_to_python_object(expected_structure)\n    expected_structure_object_string = generate_string_from_json(expected_structure)\n    return expected_structure_object_string\n\n\n\ndef convert_python_object_to_json(obj):\n    # Helper function to convert Python types to serializable types\n    def convert_type(value):\n        if isinstance(value, type):\n            return value.__name__\n        return value\n\n    # Recursively convert the object to JSON-compatible types\n    def convert(obj):\n        if isinstance(obj, dict):\n            return {key: convert(value) for key, value in obj.items()}\n        elif isinstance(obj, list):\n            return [convert(value) for value in obj]\n        else:\n            return convert_type(obj)\n\n    # Convert the object to JSON representation\n    json_representation = json.dumps(convert(obj), indent=4)\n    return json_representation\n\n\ndef extract_json_from_message(message):\n    start_token = \"{\"\n    end_token = \"}\"\n\n    # Find the start and end indices of the JSON object within the message\n    start_index = message.find(start_token)\n    end_index = message.rfind(end_token)\n\n    if start_index == -1 or end_index == -1:\n        return \"JSON object not found in the message\"\n\n    # Extract the JSON object from the message\n    json_string = message[start_index:end_index + len(end_token)]\n\n    # Parse the JSON string into a Python object\n    json_data = json.loads(json_string)\n\n    return json_data\n\n\ndef extract_json_string_from_message(message):\n    start_token = \"{\"\n    end_token = \"}\"\n\n    # Find the start and end indices of the JSON object within the message\n    start_index = message.find(start_token)\n    end_index = message.rfind(end_token)\n\n    if start_index == -1 or end_index == -1:\n        return \"JSON object not found in the message\"\n\n    # Extract the JSON object from the message\n    json_string = message[start_index:end_index + len(end_token)]\n\n    return json_string\n\n\ndef cleanup_json_response(response):\n    \n    if response.startswith(\"```json\"):\n        # Use regular expressions to extract the entire JSON block\n        json_pattern = r'```json\\s*(\\{.*?\\})\\s*```'\n        match = re.search(json_pattern, response, re.DOTALL)\n        \n        if match:\n            json_block = match.group(1)\n            try:\n                # Parse the JSON string\n                json_data = json.loads(json_block)\n                return json_block\n\n            except json.JSONDecodeError as e:\n                print(f\"Error decoding JSON: {e}\")\n                # Attempt to fix by adding a closing bracket\n                fixed_json_block = json_block + \"}\"\n                try:\n                    # Parse the fixed JSON string\n                    json_data = json.loads(fixed_json_block)\n                    return fixed_json_block\n                except json.JSONDecodeError:\n                    print(\"Failed to fix JSON.\")\n        else:\n            print(\"JSON data not found in the input string.\")\n\n    return response",
    "utils/helpers.py": "import os\nimport markdown\nimport json\n\ndef fill_gaps_with_underscore(string):\n    # Split the string by spaces\n    words = string.split()\n\n    # Create a new list to store the modified words\n    modified_words = []\n\n    # Iterate over each word\n    for word in words:\n        # If the word has gaps (multiple consecutive underscores), replace them with a single underscore\n        modified_word = word.replace('_', ' ')\n        modified_word = modified_word.replace(' ', '_')\n\n        # Add the modified word to the list\n        modified_words.append(modified_word)\n\n    # Join the modified words back into a string with spaces\n    filled_string = ' '.join(modified_words)\n\n    return filled_string",
    "prompt/prompt_context.py": "class PromptContext:\n    def __init__(self, context_dict=None, **kwargs):\n        if context_dict is None:\n            context_dict = kwargs\n\n        self.role = context_dict.get('role', '')\n        self.prefix = context_dict.get('prefix', '')\n        self.suffix = context_dict.get('suffix', '')\n        self.list_item = context_dict.get('list_item', {})\n        self.context_items = context_dict.get('context_items', {})\n        self.context = context_dict.get('context', [])\n        self.questions = context_dict.get('questions', [])\n        self.examples = context_dict.get('examples', [])\n        self.instructions = context_dict.get('instructions', [])\n        self.query = context_dict.get('query', '')\n        self.simple_prompt = context_dict.get('simplePrompt', '')\n        self.response_format = context_dict.get('response_format', '')\n        self.response_structure = context_dict.get('response_structure', '')\n\n    def clean_context(self):\n        \"\"\"\n        Reset all attributes of the instance.\n        \"\"\"\n        for key in vars(self):\n            setattr(self, key, None)\n\n    def update_context(self, update_dict):\n        \"\"\"\n        Update the context attributes based on the provided dictionary.\n        Add new attributes if they do not exist.\n        \"\"\"\n        self.clean_context()\n        for key, value in update_dict.items():\n            setattr(self, key, value)  # This will update or add a new attribute\n\n    def add_attribute(self, key, value):\n        \"\"\"\n        Add a new attribute to the instance.\n        \"\"\"\n        setattr(self, key, value)\n        \n    def get_attribute(self, key):\n        \"\"\"\n        Get the value of an attribute.\n        \"\"\"\n        return getattr(self, key)\n\n    def print_attributes(self):\n        for key, value in self.__dict__.items():\n            print(f\"{key}: {value}\")\n\n    def find_unknown_attributes(self, known_attrs):\n        \"\"\"\n        Returns a list of attribute names of the instance that are not in the known_attrs list.\n\n        :return: A list of unknown attribute names.\n        \"\"\"\n        preset_attrs = ['prefix', 'suffix', 'list_item', 'simple_prompt', 'query', 'context_items', 'questions', 'examples',\n                       'context', 'instructions', 'response_format', 'response_structure'] if not known_attrs else known_attrs\n        \n        return [attr for attr in self.__dict__ if attr not in preset_attrs]\n\n    def print_context(self):\n        # Print all attributes of the instance\n        for key in vars(self):\n            value = getattr(self, key)\n            if isinstance(value, dict):\n                print(f\"{key}:\")\n                for sub_key, sub_value in value.items():\n                    print(f\"- {sub_key}: {sub_value}\")\n            elif isinstance(value, list):\n                print(f\"{key}:\")\n                for item in value:\n                    print(f\"- {item}\")\n            else:\n                print(f\"{key}: {value}\")\n\n    def print_context(self):\n        print(\"Role:\", self.role)\n        print(\"Prefix:\", self.prefix)\n        print(\"Suffix:\", self.suffix)\n        print(\"List Item:\")\n        for key, value in self.list_item.items():\n            print(f\"- {key}: {value}\")\n        print(\"Context Items:\")\n        for key, value in self.context_items.items():\n            print(f\"- {key}: {value}\")\n        print(\"Context:\")\n        for item in self.context:\n            print(f\"- {item}\")\n        print(\"Questionaire:\")\n        for question in self.questions:\n            print(f\"- {question}\")\n        print(\"Examples:\")\n        for example in self.examples:\n            print(f\"- {example}\")            \n        print(\"Instructions:\")\n        for instruction in self.instructions:\n            print(f\"- {instruction}\")\n        print(\"Query:\", self.query)\n        print(\"Simple Prompt:\", self.simple_prompt)\n        print(\"Response Format:\", self.response_format)\n        print(\"Response Structure:\", self.response_structure)\n",
    "prompt/prompt_generator.py": "# from agents.project_items import FileList, File, FunctionalityList, Functionality, AIList\nfrom .prompt_context import PromptContext\n\ndef convert_string(string):\n    words = string.split('_')\n    converted_words = [word.capitalize() for word in words]\n    converted_string = ' '.join(converted_words)\n    return converted_string\n\n\nclass PromptGenerator:\n    def __init__(self, context: PromptContext = None, input_keys_data = None):\n        if context is not None:\n            self.set_context(context)\n        self.input_keys_data = input_keys_data\n\n    def set_context(self, context):\n        self.promptcontext = context\n        self.prefix = context.prefix or \"\"\n        self.suffix = context.suffix or \"\"\n        self.list_item = context.list_item or {}\n        self.prompt = context.simple_prompt or \"\"\n        self.context_items = context.context_items or []\n        self.questions = context.questions or []\n        self.examples = context.examples or []\n        self.context = context.context or []\n        self.instructions = context.instructions or []\n        self.query = context.query or \"\"\n        self.response_format = context.response_format or \"\"\n        self.response_structure = context.response_structure or \"\"\n\n    def generate_prompt(self):\n        # Handle additional dynamic attributes\n        known_attrs = ['role', 'prefix', 'suffix', 'list_item', 'simple_prompt', 'query', 'context_items', 'questions', 'examples',\n                       'context', 'instructions', 'response_format', 'response_structure']\n        # additional_attrs = [attr for attr in additional_attrs if not callable(getattr(self.context, attr))]\n        additional_attrs = self.promptcontext.find_unknown_attributes(known_attrs)\n\n        prompt = \"\"\n        \n        if self.prefix != \"\" and self.prefix is not None:\n            prompt = f\"{self.prefix}\\n\\n\"\n        \n        prompt += f\"## Prompt:\\n{self.prompt}.\"\n        \n        if self.response_format != \"\" and self.response_format is not None:\n            prompt += \" \" + f\"Please provide your response in {self.response_format} format\"\n            prompt += \" \" + f\"and in the requested structure which is shown below.\"\n            prompt += \"\\n\\n\"\n        else:\n            prompt += \"\\n\\n\"\n        \n\n        if self.query != \"\" and self.query is not None:\n            prompt += f\"## Query:\\n{self.query}\\n\\n\"\n        \n        if self.list_item and self.list_item is not None:\n            prompt += \"## Current List Item:\\n\"\n            for key, value in self.list_item.items():\n                prompt += f\"- {key}: {value}\\n\"\n            prompt += \"\\n\"\n\n        if additional_attrs and additional_attrs is not None:\n            prompt += \"## Additional Context:\\n\"\n            for attr in additional_attrs:\n                value = getattr(self.promptcontext, attr)\n                prompt += f\"- {attr}: {value}\\n\"\n            prompt += \"\\n\"\n\n        if self.context or self.context_items or self.input_keys_data is not None:\n            prompt += \"## Context:\\n\"\n            \n            if self.context and self.context is not None:\n                for context_item in self.context:\n                    prompt += f\"- {context_item}\\n\"\n                    \n            if self.context_items and self.context_items is not None:\n                for context_item in self.context_items.items():\n                    key , context = context_item\n                    # print()\n                    # print (\"checking key: \", key)\n                    # print (context)\n                    # print (type(context))\n                    # print (isinstance(context, FileList))\n                    # print (isinstance(context, FunctionalityList))\n                    # print (isinstance(context, Functionality))\n                    # print (isinstance(context, File))\n                    # print (isinstance(context, str))\n                    \n                    ## if isinstance(context, FileList):\n                    ##     file_list_prompt = context.generate_file_list_context()\n                    ##     prompt += file_list_prompt + \"\\n\"\n                    ## elif isinstance(context, FunctionalityList):\n                    ##     functionality_list_prompt = context.generate_functionality_context()\n                    ##     prompt += functionality_list_prompt + \"\\n\"\n                    ## elif isinstance(context, AIList):\n                    ##     ailist_prompt = context.generate_context()\n                    ##     prompt += ailist_prompt + \"\\n\"\n                    ## else:\n                    ##     key, context = context_item\n                    ##     prompt += f\"- {key}: {context}\\n\"\n                    \n                    prompt += f\"- {key}: {context}\\n\"\n            \n            if self.input_keys_data:\n                for key, value in self.input_keys_data.items():\n                    prompt += f\"- {key}: {value}\\n\"\n\n            prompt += \"\\n\"\n\n        if self.instructions and self.instructions is not None:\n            prompt += \"## Instructions:\\n\"\n            for idx, instruction in enumerate(self.instructions, start=1):\n                prompt += f\"{idx}. {instruction}\\n\"\n            prompt += \"\\n\"\n\n        if self.questions and self.questions is not None:\n            prompt += \"## Questionaire:\\n\"\n            for idx, question in enumerate(self.questions, start=1):\n                prompt += f\"{idx}. {question}\\n\"\n            prompt += \"\\n\"\n\n        if self.examples and self.examples is not None:\n            prompt += \"## Examples:\\n\"\n            for idx, example in enumerate(self.examples, start=1):\n                prompt += f\"{idx}. {example}\\n\"\n            prompt += \"\\n\"\n\n        if self.response_format != \"\" and self.response_format is not None:\n            prompt += \"## Response Format:\\n\"\n            prompt += f\"Remember to provide your response in the format: {self.response_format}\\n\\n\"\n\n        if self.response_structure != \"\" and self.response_structure is not None:\n            prompt += \"## Expected Structure:\\n\"\n            prompt += f\"{self.response_structure}\\n\\n\"\n\n        prompt += f\"{self.suffix}\\n\"\n        \n        return prompt\n\n\n\n    def set_prompt_prefix(self, prefix = \"\"):\n        \n        if prefix == \"\":\n            prompt_prefix = f\"\"\"## Project:\\nPlease complete below instructions to complete the task. Provide your response in the given response format and in the expected structure.\\n\\n\"\"\"\n        else:\n            prompt_prefix = prefix\n\n        self.prompt_prefix = prompt_prefix\n        \n        return prompt_prefix\n\n\n    def set_prompt_instructions(self, instructions = None):\n        \n        prompt_text = \"\"\n                \n        if instructions is not None:\n            prompt_text += f\"\\n\\n## Instructions:\\n\"\n            for instruction in instructions:\n                prompt_text += \"- \" + instruction + \"\\n\"\n\n        self.prompt_body = prompt_text\n        \n        return prompt_text\n    \n    \n    def set_prompt_body(self, prompt = \"\", prompt_body_items = None):\n        prompt_text = \"\"\n        \n        if prompt != \"\":\n            prompt_text = f\"\"\"## Task:\\n{prompt}\\n\"\"\"\n        else:\n            prompt_text = prompt\n        \n        if prompt_body_items is not None:\n            for placeholder, replacement in prompt_body_items.items():\n                \n                placeholder_title = convert_string(placeholder)\n\n                prompt_text += f\"\\n\\n## {placeholder_title}:\\n{{{{{placeholder}}}}}\\n\"\n                placeholder = \"{{\" + placeholder + \"}}\"\n                prompt_text = prompt_text.replace(placeholder, replacement)\n\n\n        self.prompt_body = prompt_text\n        \n        return prompt_text\n\n        \n\n    def set_prompt_suffix(self, response_format = \"json\", expected_structure = \"{ \\\"key\\\": \\\"value\\\"}\"):\n\n        prompt_suffix = f\"\\n## Response Format:\\nRemember to provide your response in minified {response_format} format.In order to save tokens also avoid line breaks in the minified response. Do not add any further comments for automatic processing of the response.\\n\"\n\n        if expected_structure and expected_structure != \"{}\":\n            prompt_suffix += f\"\\n## Expected Structure:\\n{expected_structure}\\n\"\n\n        self.prompt_suffix = prompt_suffix\n        \n        return prompt_suffix\n        \n    def prepare_prompt_builder(self):\n        self.set_prompt_prefix()\n        self.set_prompt_body()\n        self.set_prompt_suffix()\n        self.set_prompt_instructions()\n        self.use_prompt_builder = True",
    "prompt/response_processor.py": "class ResponseProcessor:\n    def __init__(self, response_format):\n        self.format = response_format\n\n    def process_response(self, response):\n        # Implementation to process the NLP response into a structured JSON output\n        # Placeholder for response processing logic\n        print(f\"Processing response: {response}\")\n        return response\n",
    "memory_management/memory_manager.py": "import json\n\nclass ModuleMemory:\n    def __init__(self):\n        self.memory_store = {}\n\n    def _navigate_to_node(self, path_list, create_missing=False):\n        \"\"\"\n        Navigate to the node specified by the path list.\n        If create_missing is True, missing nodes along the path will be created.\n        \"\"\"\n        current_node = self.memory_store\n        for key in path_list[:-1]:\n            if key not in current_node:\n                if create_missing:\n                    current_node[key] = {}\n                else:\n                    raise KeyError(f\"Path '{' > '.join(path_list)}' does not exist.\")\n            current_node = current_node[key]\n        return current_node, path_list[-1]\n\n    def save_response(self, response):\n        \"\"\"\n        Save the response from OpenAI to memory.\n        \"\"\"\n        self.memory_store['response'] = response\n        \n    def get_response(self):\n        \"\"\"\n        Get the response from memory.\n        \"\"\"\n        return self.memory_store.get('response')\n\n    def create(self, path_list, value):\n        \"\"\"\n        Create a new entry in memory at the specified path.\n        \"\"\"\n        node, key = self._navigate_to_node(path_list, create_missing=True)\n        if key in node:\n            raise KeyError(f\"Key '{key}' already exists at path '{' > '.join(path_list)}'.\")\n        node[key] = value\n\n    def read(self, path_list):\n        \"\"\"\n        Read an entry from memory at the specified path.\n        \"\"\"\n        \n        try:\n            node, key = self._navigate_to_node(path_list)\n        except KeyError:\n            return None\n        \n        return node.get(key)\n\n    def update(self, path_list, value):\n        \"\"\"\n        Update an existing entry in memory at the specified path.\n        \"\"\"\n        node, key = self._navigate_to_node(path_list)\n        if key not in node:\n            raise KeyError(f\"Key '{key}' not found at path '{' > '.join(path_list)}'.\")\n        node[key] = value\n        \n    def create_or_update(self, path_list, value):\n        \"\"\"\n        Create a new entry in memory at the specified path if it doesn't exist,\n        otherwise update the existing entry.\n        \"\"\"\n        node, key = self._navigate_to_node(path_list, create_missing=True)\n        node[key] = value\n\n    def delete(self, path_list):\n        \"\"\"\n        Delete an entry from memory at the specified path.\n        \"\"\"\n        node, key = self._navigate_to_node(path_list)\n        if key in node:\n            del node[key]\n\n\n    def exists(self, key):\n        \"\"\"\n        Check if a key exists in memory.\n        \"\"\"\n        return key in self.memory_store\n\n    def get_all_keys(self):\n        \"\"\"\n        Get all keys in memory.\n        \"\"\"\n        return list(self.memory_store.keys())\n\n    def save_to_file(self, file_path):\n        \"\"\"Saves the current state of memory to a JSON file.\"\"\"\n        with open(file_path, 'w') as file:\n            json.dump(self.memory_store, file, indent=4, sort_keys=True)\n\n    def load_from_file(self, file_path):\n        \"\"\"Loads the current state of memory from a JSON file.\"\"\"\n        with open(file_path, 'r') as file:\n            self.memory_store = json.load(file)",
    "nlp/nlp_processor.py": "import json\nimport os\nfrom datetime import datetime\nfrom .nlp_client import NLPClient\nfrom ai.utils import extract_json_from_message, extract_json_string_from_message, cleanup_json_response\nfrom ai.utils import fill_gaps_with_underscore, verify_json\nfrom typing import List\nfrom ai.memory_management import ModuleMemory\n\nclass NLPProcessor:\n    def __init__(self, memory: ModuleMemory = None, nlp_client: NLPClient = None, project_path=None, prompt_path=None, response_path=None):\n        self.memory = memory\n        self.nlp_client = nlp_client if nlp_client else NLPClient()\n        self.project_path = self.memory.read([\"project\", \"files\", \"project_folder\"])\n        self.prompt_path = self.memory.read([\"project\", \"files\", \"prompt_folder\"])\n        self.response_path = self.memory.read([\"project\", \"files\", \"response_folder\"])\n        self.output_path = self.memory.read([\"project\", \"files\", \"output_folder\"])\n        self.counter = 0\n\n    def set_project_path(self, project_path):\n        self.project_path = project_path\n\n    def set_prompt_path(self, prompt_path):\n        self.prompt_path = prompt_path\n\n    def set_response_path(self, response_path):\n        self.response_path = response_path\n\n    def process(self, prompt, context):\n        \"\"\"Process the query using the NLP system.\"\"\"\n\n        role = context.role or \"GPT Manager\"\n        prompt = prompt\n        response_format = context.response_format or \"json\"\n        response_structure = context.response_structure or \"\"\"{ \"data\" : { \"response\" : \"str\" }}\"\"\"\n\n        response = self.get_response(role, prompt, response_format, response_structure, \"\", True)\n        #### response = self.nlp_client.process(query)\n\n        content = self.process_response(response)\n\n        return content\n\n    def save_item(self, role, toggle, file_suffix, item):\n        # Save item to a text file\n        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n        filename = f\"{toggle}_{self.counter}_{role}{file_suffix}_{timestamp}.md\"\n\n        if toggle == \"Prompt\":\n            save_folder = self.prompt_path\n        elif toggle == \"Response\":\n            save_folder = self.response_path\n        else:\n            save_folder = self.project_path\n            \n        print (\"save_folder: \", save_folder)\n        print (\"filename: \", filename)\n        file_path = os.path.join(save_folder, filename)\n\n        with open(file_path, \"w\") as file:\n            file.write(f\"### {toggle} (time: {timestamp})\\n\\n\")\n            file.write(item)\n            \n\n    def get_verified_response_single(self, role, prompt: str, response_format, response_structure) -> str:\n        retries = 10\n        \n        output_path = self.memory.read([\"project\", \"files\", \"output_folder\"])\n        \n        while retries > 0:\n\n            # Call the GPT-4 model for each prompt and get the response\n            original_response = self.nlp_client.process(prompt, role)\n            \n            response = cleanup_json_response(original_response)\n            \n            ##### response_structure = response_structure.replace('bool', 'True')\n\n            # Save failed response as a .md file\n            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n\n            file_name = \"__response_collection_\" + timestamp + \".md\"\n            output_filename = os.path.join(self.output_path, file_name)\n            \n            original_file_name = \"__response_original_collection_\" + timestamp + \".md\"\n            original_output_filename = os.path.join(self.output_path, original_file_name)\n            \n            try :\n                with open(original_output_filename, \"w\") as f:\n                    f.write(original_response)\n                with open(output_filename, \"w\") as f:\n                    f.write(response)\n            except:\n                print ()\n                print ()\n                print (\"--------------------------------\")\n                print (\"failed to write response to file\")\n                print (\"--------------------------------\")\n                print ()\n                print ()\n                print (\"original_response: \", original_response)\n                print (\"--------------------------------\")\n                print ()\n                print ()\n                print (\"response: \", response)\n                print (\"--------------------------------\")\n                print ()\n                print ()\n                pass\n            \n            if response_format == \"markdown\":\n                return response\n            \n            # Verify the response against the JSON structure\n            if verify_json(response, response_structure):\n                return response\n            \n            print (\"response verification failed, retries left: \", retries)\n            # input (\"press enter to continue\")\n\n            retries -= 1\n        \n        self.safe_error_prompt(prompt, role, response, response_structure)\n        # If verification fails after all retries, raise an exception or handle it as needed\n        raise Exception(\"Response verification failed after retries.\")\n\n    def safe_error_prompt(self, prompt, role_name, response, response_structure):\n\n        # Save failed prompt as a .md file\n        file_name = \"__failed_prompt_\" + role_name + \".md\"\n        output_filename = os.path.join(self.output_path, file_name)\n        with open(output_filename, \"w\") as f:\n            f.write(prompt)\n\n        # Save failed response as a .md file\n        file_name = \"__failed_response_\" + role_name + \".md\"\n        output_filename = os.path.join(self.output_path, file_name)\n        with open(output_filename, \"w\") as f:\n            f.write(response)\n\n        # Save failed structure as a .md file\n        file_name = \"__failed__structure_\" + role_name + \".md\"\n        output_filename = os.path.join(self.output_path, file_name)\n        \n        if isinstance(response_structure, dict):\n            response_structure = json.dumps(response_structure)\n            \n        with open(output_filename, \"w\") as f:\n            f.write(response_structure)\n\n    \n\n    def get_verified_response(self, role, prompts: List[str], response_format, response_structure) -> str:\n        \"\"\"\n        Sends the prompt array to the GPT model for verification and receives verification feedback\n        \"\"\"\n        responses = []\n        \n        i = 0\n        role_name = fill_gaps_with_underscore(role)\n        for prompt in prompts:\n            i += 1\n\n            print(f\"{role} is working on: prompt {i} of {len(prompts)}\")\n            verified_response = self.get_verified_response_single(role, prompt, response_format, response_structure)\n\n            # Save verification results as a .md file\n            file_name = \"prompt_\" + role_name + \".md\"\n            file_name = file_name.replace(\"..\", \".\")\n            output_filename = os.path.join(self.project_path, \"output\", file_name)\n            with open(output_filename, \"w\") as f:\n                f.write(prompt)\n\n            # Save verification results as a .md file\n            file_name = \"response_\" + role_name + \".md\"\n            file_name = file_name.replace(\"..\", \".\")\n            output_filename = os.path.join(self.project_path, \"output\", file_name)\n            with open(output_filename, \"w\") as f:\n                f.write(verified_response)\n\n\n            responses.append(verified_response)\n\n        return \"\\n\".join(responses)\n    \n    \n    def submit_prompt(self, nlp_client, prompttext, role = \"You are a award winning web developer\", response_format = \"json\", response_structure = \"\"):\n        # Use the get_verified_response method of your GPTModel class to send the prompttext for verification\n        response = self.get_verified_response(role , [prompttext], response_format, response_structure)\n        return response\n\n    def init_folders(self):\n        self.project_path = self.memory.read([\"project\", \"files\", \"project_folder\"])\n        self.prompt_path = self.memory.read([\"project\", \"files\", \"prompt_folder\"])\n        self.response_path = self.memory.read([\"project\", \"files\", \"response_folder\"])\n        self.output_path = self.memory.read([\"project\", \"files\", \"output_folder\"])\n\n\n    def get_response(self, role, prompt, response_format, response_structure = \"\", item_number = '', extract_json = True):\n        \n        self.init_folders()\n        \n        if item_number == '':\n            file_suffix = ''\n        else:\n            file_suffix = \"_\" + item_number\n        \n        # Save prompt to a text file\n        self.save_item(role, \"Prompt\", file_suffix, prompt)\n\n        # Generate response\n        response = self.submit_prompt(self.nlp_client, prompt, role, response_format, response_structure)\n        \n        if extract_json and response_format == \"json\": \n            response = extract_json_string_from_message(response)\n\n        # Save response to a text file\n        self.save_item(role, \"Response\", file_suffix, response)\n\n        self.counter += 1\n\n        return response\n    \n    def process_response(self, response):\n        # Implement your response processing logic here\n        processed_response = response  # Placeholder implementation, modify as needed\n        return processed_response\n    \n    def to_json(self):\n        # Serialize the NLPProcessor object to JSON.\n        # This includes the serialization of the NLPClient.\n        return json.dumps({\n            \"class\": \"NLPProcessor\",\n            \"nlp_client\": self.nlp_client.to_json()\n        })\n\n    @classmethod\n    def from_json(cls, json_str):\n        # Deserialize the JSON string back to an NLPProcessor object.\n        data = json.loads(json_str)\n        nlp_client = NLPClient.from_json(data[\"nlp_client\"])\n        return cls(nlp_client=nlp_client)\n",
    "nlp/nlp_client.py": "import time\nimport logging\nimport tiktoken\nimport os\nimport json\nimport openai\nfrom openai import OpenAI\n\nGPT_MODEL = \"gpt-4-1106-preview\"\nGPT_MODEL = \"gpt-3.5-turbo-1106\"\n\nRETRY_COUNT = 0\nMAX_RETRIES = 50\nWAIT_TIME = 5\n\nclass NLPClient:\n    def __init__(self):\n        pass\n\n    def process(self, prompt, role):\n        client = OpenAI()\n        retry_count = RETRY_COUNT\n        wait_time = WAIT_TIME\n\n\n        while retry_count < MAX_RETRIES:\n            try:\n                #Make your OpenAI API request here\n                response = client.chat.completions.create(\n                    model=GPT_MODEL,\n                    messages=[\n                        {\"role\": \"system\", \"content\": role},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ]\n                )\n                break\n\n            except openai.APIError as e:\n                logging.error(f\"OpenAI API Error: {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 1\n                \n            except openai.APIConnectionError as e:\n                logging.error(f\"OpenAI API Connection Error: {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 1\n\n            except openai.APITimeoutError as e:\n                logging.error(f\"OpenAI Timeout Error: {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 1\n\n            except openai.RateLimitError as e:\n                logging.error(f\"OpenAI Rate Limit Error (You have hit your assigned rate limit): {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 1\n                \n            except openai.InternalServerError as e:\n                logging.error(f\"OpenAI Internal Server Error: {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 1\n                                \n            except openai.AuthenticationError as e:\n                logging.error(f\"OpenAI Authentication Error: {str(e)}\")\n                break\n            \n            except openai.BadRequestError as e:\n                logging.error(f\"OpenAI Bad Request Error (Your request was malformed or missing some required parameters, such as a token or an input): {str(e)}\")\n                break\n            \n            except openai.ConflictError as e:\n                logging.error(f\"OpenAI Conflict Error (The resource was updated by another request): {str(e)}\")\n                break\n            \n            except openai.NotFoundError as e:\n                logging.error(f\"OpenAI Not Found Error (Requested resource does not exist.): {str(e)}\")\n                break\n            \n            except openai.PermissionDeniedError as e:\n                logging.error(f\"OpenAI Permission Denied Error (You don't have access to the requested resource.): {str(e)}\")\n                break\n                        \n            except openai.UnprocessableEntityError as e:\n                logging.error(f\"OpenAI Unprocessable Entity Error (Unable to process the request despite the format being correct): {str(e)}\")\n                break\n            \n            except Exception as e:\n                logging.error(f\"Unexpected Error: {str(e)}\")\n                wait_time += 5\n                print(f\"OpenAI: Retrying in {wait_time} seconds, retry count: {retry_count}...\")\n                time.sleep(wait_time)\n                retry_count += 10\n                \n            retry_count += 1\n\n        response = response.choices[0].message.content\n        \n        print (\"prompt processed by NLPClient\")\n        \n        return response\n\n    def process_as_json(self, prompt, role):\n        client = OpenAI()\n\n        response = client.chat.completions.create(\n            model=\"gpt-4-1106-preview\",\n            response_format={ \"type\": \"json_object\" },\n            messages=[\n                {\"role\": \"system\", \"content\": role},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n        )\n\n        return response.choices[0].message.content\n\n    def to_json(self):\n        # Serialize the NLPClient object to JSON.\n        # Note: since this class does not contain any dynamic data, \n        # we return a basic representation.\n        return json.dumps({\"class\": \"NLPClient\"})\n\n    @classmethod\n    def from_json(cls, json_str):\n        # Deserialize the JSON string back to an NLPClient object.\n        # Since there's no dynamic data, we simply return a new instance.\n        return cls()",
    "api/api_key_loader.py": "import os\nimport logging\nfrom dotenv import load_dotenv\n\nclass OpenAIKeyLoader:\n    def __init__(self, dotenv_path=None):\n\n        # Check if the .env file exists before trying to load it\n        if dotenv_path is None or not os.path.exists(dotenv_path):\n            raise FileNotFoundError(f\"The .env file was not found at {dotenv_path}\")\n\n        # Load environment variables from the .env file\n        load_dotenv(dotenv_path)\n\n        # Get the OpenAI API Key\n        self.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\n        try:\n            api_key = os.environ.get('OPENAI_API_KEY')\n            if not api_key:\n                raise ValueError(\"API key not found in .env file.\")\n            self.api_key = api_key\n            logging.info(\"API Key loaded successfully.\")\n        except Exception as e:\n            logging.error(f\"Error loading API key: {e}. Please check the .env file.\")\n            raise\n\n    def get_api_key(self):\n        return self.api_key\n",
    "LICENSE": "MIT License\n\nCopyright (c) 2024 mxn2020\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
    "maldinio_ai.egg-info/PKG-INFO": "Metadata-Version: 2.1\nName: maldinio-ai\nVersion: 0.1.1\nSummary: A utility package for AI prompt management and prompt processing.\nAuthor: Mehdi Nabhani\nAuthor-email: mehdi@nabhani.de\nKeywords: AI,NLP,LLM,Prompt Management\nLicense-File: LICENSE\n",
    "maldinio_ai.egg-info/SOURCES.txt": "LICENSE\nREADME.md\nsetup.py\napi/__init__.py\napi/api_key_loader.py\nmaldinio_ai.egg-info/PKG-INFO\nmaldinio_ai.egg-info/SOURCES.txt\nmaldinio_ai.egg-info/dependency_links.txt\nmaldinio_ai.egg-info/requires.txt\nmaldinio_ai.egg-info/top_level.txt\nmemory_management/__init__.py\nmemory_management/memory_manager.py\nnlp/__init__.py\nnlp/nlp_client.py\nnlp/nlp_processor.py\nprompt/__init__.py\nprompt/prompt_context.py\nprompt/prompt_generator.py\nprompt/response_processor.py\ntools/__init__.py\ntools/create_project_folder.py\ntools/load_project.py\nutils/__init__.py\nutils/helpers.py\nutils/json_utils.py\nutils/verification_utils.py",
    "maldinio_ai.egg-info/requires.txt": "tiktoken>=0.4.0\nopenai>=1.3.7\n",
    "maldinio_ai.egg-info/top_level.txt": "api\nmemory_management\nnlp\nprompt\ntools\nutils\n",
    "maldinio_ai.egg-info/dependency_links.txt": "\n"
}